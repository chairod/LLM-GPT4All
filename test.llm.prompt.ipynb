{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## สคลิปทดสอบนี้ ใช้สำหรับ ทดสอบผ่านข้อความให้กับ LLM แล้ว\n",
    "## ใช้คำถาม ถามตามข้อความที่ส่งให้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program Files\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from constants import *\n",
    "from gpt4allV1_3 import pyllmodel\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "model_path = f'{LLM_MODEL_PATH}\\\\{LLM_MODEL_NAME}'\n",
    "llm = pyllmodel.LLModel()\n",
    "llm.load_model(model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, you can't deposit more than 20,000 baht in one transaction."
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"No, you can't deposit more than 20,000 baht in one transaction.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_str = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer, answer short questions without explanation, make up an answer of no more than 3 sentences, there must be no test cases out there in the answer.\n",
    "\n",
    "    Users can deposit cash amounts between 9.00-17.00 If the user�s age is between 12- and 15 years old the fee amount charged is 0.00 baht.\n",
    "    Feature: Deposit cash balance Conditions: Users can�t deposit cash amounts over 20,000 baht per transaction.\n",
    "    Users can�t deposit cash amounts over 500,000 baht per day.\n",
    "    If the user�s age is over 15 years old the fee amount charged is 15 baht per transaction.\n",
    "    1. Test Case of Unit Testing 2. Test Case of Integration Testing 3. Test Scenario of End-to-End Testing\n",
    "\n",
    "    Question: Can I deposit more than 20,000 baht in one transaction?\n",
    "    Helpful Answer:\n",
    "\"\"\"\n",
    "# \n",
    "\n",
    "llm.prompt_model(\n",
    "     prompt=query_str,\n",
    "        streaming=True,\n",
    "        reset_context=True,\n",
    "\n",
    "        # ค่าอยู่ระหว่าง 0 - 1 เช่น 0.1, 0.2, 0.3, 0.4, ..., 1\n",
    "        # เป็นค่าความคิดสร้างสรรค์ ในการตอบคำถามของ LLM\n",
    "        # นัยสำคัญของ Fine-tune:\n",
    "        #   ค่า temp จะมีนัยสำคัญในการนำข้อความ ที่ผ่านให้กับ LLM ด้วย Prompt โดย LLM จะนำ Prompt นั้นมาวิเคราะห์ข้อความที่อยู่ภายใน Prompt เพื่อให้ได้ซึ่งคำตอบ\n",
    "        # ตัวอย่างเช่น:\n",
    "        #   Feature: Deposit cash balance Conditions: Users can't deposit cash amounts over 20,000 baht per transaction.\\n \n",
    "        # Users can’t deposit cash amounts over 500,000 baht per day.\\n\n",
    "        # Users can deposit cash amounts between 9.00-17.00 If the user’s age is between 12- and 15 years old the fee amount charged is 0.00 baht.\\n\n",
    "        #\n",
    "        #  Question: Can I deposit more than 500,000 baht per day?\n",
    "        #  ถ้ากำหนด temp = 0.3 คำตอบที่ได้จะเป็น Yes เสมอ\n",
    "        #  ถ้ากำหนด temp = 0.5 คำตอบที่ได้จะเป็น No แต่รูปแบบประโยค ยังไม่สมบูรณ์\n",
    "        #  ถ้ากำหนด temp = 0.6 คำตอบที่ได้จะเป็น No แต่รูปแบบประโยค ยังไม่สมบูรณ์ แต่ทิศทางดีกว่า temp = 0.5\n",
    "        #  ถ้ากำหนด temp = 0.7 คำตอบที่ได้จะเป็น No แต่รูปแบบประโยค เริ่มสมบูรณ์ขึ้น แต่ยังมีบางส่วนที่ต้องแก้ไข\n",
    "        #  ถ้ากำหนด temp = 0.8 คำตอบที่ได้จะเป็น No รูปแบบประโยคเริ่มถูกต้อง และมีทิศทางทีดี (แนะนำให้ใช้ค่าประมาณนี้)\n",
    "        #\n",
    "        # คำแนะนำและบริษทในการปรับค่า:\n",
    "        #   A. หากนำ LLM นี้ไปใช้งานในเอกสารที่เป็น ลักษณะ Q & A ซึ่งมีคำถามและคำตอบ ในเนื้อหาอยู่แล้ว แนะนำให้ใช้ค่าที่ 0.3 ก็เพียงพอแล้ว\n",
    "        #   B. หากนำ LLM นี้ไปใช้งานในเอกสารที่มีเนื้อหา ที่ต้องการให้ LLM นำเนื้อหานั้นมาวิเคราะห์ข้อความ เพื่อสังเคราะห์ออกมาเป็นคำตอบให้ปรับค่าเป็น 0.8 จะถือเป็นค่าที่เหมาะสม\n",
    "        temp=0.3,\n",
    "\n",
    "\n",
    "        # จำนวน Token (ชุดของข้อความที่มีความเป็นไปได้ ที่ใกล้งเคียงกับคำถาม) ที่บอกให้ LLM หยิบมาใช้ในการสร้างประโยคคำตอบ\n",
    "        # ซึ่งรายการ Token ที่ได้จะถูกจัดลำดับ (sort) ตามความน่าจะเป็นที่ มากสุดไปน้อย สุด\n",
    "        # ค่านี้จะมีผลต่อ ความยาวของประโยคคำตอบ\n",
    "        # กำหนดค่านี้เป็น 1 จะได้ประโยคคำตอบที่สั้นและกระชับ\n",
    "        top_k=1, \n",
    "\n",
    "\n",
    "        # ผลรวม % จากจำนวนทั้งหมดของ top_k (คือ 20 รายการ)\n",
    "        # จะต้องได้ >= top_p ถึงจะออกมาเป็นคำตอบ\n",
    "        # หลักๆ แล้วจะใช้ในการ กรองข้อมูล Token ที่มีความน่าจะเป็น ของคำตอบน้อย ออกไป\n",
    "        top_p=0.9,\n",
    "\n",
    "        # จำนวนคำ (Token) สูงสุด ที่นำมาสร้างเป็นรูปประโยคคำตอบ สูงสุดไม่เกินจำนวนกี่คำ\n",
    "        # หากเกินจำนวนคำที่กำหนดแล้ว ถึงแม้ประโยคจะไม่สมบูรณ์ ก็จะหยุดสร้างคำตอบทันที (Stop Generate Text)\n",
    "        n_predict = 128,\n",
    "\n",
    "\n",
    "        # จำนวน Prediction (การคาดการณ์/การทำนาย คำถาม หรือ จำนวนคำถาม) ที่จะเกิดขึ้นระหว่างการสร้างคำตอบ (Generate text)\n",
    "        # ส่วนใหญ่จะเกิดในกรณีที่ Q & A\n",
    "        # เช่น\n",
    "        # Q: Is it possible to buy and sell shares when the Share Status is CLOSEONLY? \\\n",
    "        # A: No, it is not possible to buy and sell shares when the Share Status is CLOSEONLY.\n",
    "        # What are the possible values for the CanBuy and CanSell Account Status options?\n",
    "        #\n",
    "        # เมื่อ LLM สร้างคำตอบ สิ่งที่ได้จะเป็นส่วนของ A (Answer) และมีคำถามติดมาด้วย What are ...\n",
    "        # หากกำหนดค่า n_batch 2,3,4,5, ... LLM ก็จะค้นหาคำตอบเพิ่มเติมจากคำถามที่พบ\n",
    "        n_batch=1500,\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        #repeat_penalty = 0,\n",
    "        #repeat_last_n = 0,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
