+ 08/07/2023
  > Update python package "gpt4all" จาก Version 0.3 -> 1.3 ผลที่ได้ 
    1.) คำตอบตรงกับสิ่งที่ถาม แต่ ยังมีคำตอบบางส่วนเกิน จากคำถามอยู่แบ้าง และได้ลองปรับจูน ค่าแล้วแต่ยังไม่เป็นผล (top_k = 1, n_batch = 1, temp = 0.1)
    2.) การสร้างคำตอบช้ากว่า version 0.3 แต่ได้คำตอบแม่นยำกว่า
        Resource เครื่องที่ทดสอบ: NB Lenovo
        CPU: Core i7 gen 10 1.5GHz
        RAM: 32GB
        HHD: 2TB
        SSD: 256GB
    3.) มีการปัดบรรทัดใหม่ให้ แต่ V. 0.3 ไม่มี

  > ลองเทียบผลระหว่าง GPT4all & ChatGPT/OpenAI ผลที่ได้
    1.) ChatGPT/OpenAI ให้คำตอบที่แม่นยำ และ เร็ว (ไม่เกิน 1 sec)
    2.) GPT4All ตอบเช้า 10 sec. เป็นอย่างน้อยและคำตอบ เยิ้นเย้อ ตอบไม่ตรงคำตอบ (V. 0.3)

  > GPT4all V1.3 สร้างคำตอบได้ดีขึ้นกว่า V0.3
    เพราะลองใช้ Model ggml-gpt4all-j-v1.3-groovy.bin รันบน V0.3 & V1.3 ผลที่ได้ V1.3 ได้ผลดีกว่าตอบได้ถูกต้องมากกว่า
    เดิมเคยตั้งสมมุติฐาน เกิดจาก Model ที่เทรนด์มามีข้อบกพร่องบางอย่าง เป็นผลทำให้คำตอบออกมามีความคาดเคลื่อน (เพี้ยน) จากคำถาม หรือในบางครั้งตอบเพี้ยนไป คนละความหมายกับสิ่งที่ถาม

    แต่ข้อสรุปที่ได้เกิดจาก C-API ของ GPT4All ซึ่งเป็น backend service ที่ใช้ Model ภาษา (Deep Trained) มาประมวลไวยากรณ์ภาษา และ รูปแบบประโยค



+ 05/07/2023
  > จริงๆแล้ว PromptTemplate จะมีส่วนสำคัญมากในการ ส่งเนื้อหาให้กับ LLM สร้างคำตอบ
โดยการเขียน PromptTemplate ที่ดีจะเป็นอีก 1 ปัจจัยในการสร้างคำตอบของ LLM เช่น คำตอบไม่มากไป 
ตย.: ของ Langchain
D:\Program Files\Python310\Lib\site-packages\langchain\chains\question_answering\stuff_prompt.py


+ 03/07/2023
  > ทำความเข้าใจใน Parameter temp ซึ่งค่านี้จะมีส่วนสำคัญในการ วิเคราะห์ข้อความและการสร้างสรรค์คำตอบ ด้วย เช่น
  ตัวอย่างเช่น:  ผ่านค่าชุด Prompt นี้ให้กับ LLM
  
    Feature: Deposit cash balance Conditions: Users can't deposit cash amounts over 20,000 baht per transaction.\n 
    Users can’t deposit cash amounts over 500,000 baht per day.\n
    Users can deposit cash amounts between 9.00-17.00 If the user’s age is between 12- and 15 years old the fee amount charged is 0.00 baht.\n
    
    Question: Can I deposit more than 500,000 baht per day?
    ถ้ากำหนด temp = 0.3 คำตอบที่ได้จะเป็น Yes เสมอ
    ถ้ากำหนด tmp = 0.8 คำตอบที่ได้จะเป็น No ตามเนื้อหาและบริบทข้อความ ที่ส่งไปกับ Prompt



+ 02/07/2023
 > พบปัญหาการใช้งาน PromptTemplate ของ Langchain
  ชุดข้อความที่ส่งให้กับ PromptTemplate จะมีรูปแบบ EOS (End-Of-Seqeuence หรือ Stop Sequence) เพื่อบอกให้ LLM สิ้นสุดการสร้างคำตอบเมื่อเจอ .\n

  Test Case:
    Case 1: Langchain PromptTemplate
      ใช้ PromptTemplate ของ Langchain และ ส่งค่าที่ได้ให้กับ LLM  เมื่อ LLM สร้างคำตอบ กลับทำให้ .\n ที่เป็น End-Of-Sequence หรือ Stop Sequence ไม่เป็นผล และมีการสร้างคำถามเพิ่มเติมอีก....

    Case 2: ใช้ variable str = "{query_result_ai_db}\n\nQuestion: {user_question}\n\n"
      เมื่อ LLM สร้างคำตอบรูปแบบ End-Of-Sequence หรือ Stop Sequence ยังคงถูกรักษาไว้ และเมื่อ LLM เจอ .\n ก็หยุดสร้างคำตอบปกติ

  
  > Chromadb เมื่อส่งคำถามที่มี ' (single-quote) จะตี Error ออกมา เช่น "Can I deposit cash into someone else's account?"
  จะได้ Error:
    ParserException: Parser Error: syntax error at or near "s"
    LINE 1: ...('Can I deposit cash into someone else's account?' in document) > 0 AND collec...

    *** อยู่ระหว่างการหาวิธีการแก้ไข ***
    แก้ชั่วคราวโดยการ replace ' => \x027 (Unicode)

  > ChromaDb ถ้าส่งคำถามที่มี space (อยู่ด้านหน้าหรือหลัง) จะมีผลต่อการค้นหา ดังนั้นแนะนำให้ .strip() หรือเป็นการ trim space ออกไปจากข้อความก่อน






+ 01/07/2023
 > มีรูปแบบ ประโยค หรือ ประโยคคำถามที่่ใกล้เคียงกัน (ต่างกันเพียงไม่กี่คำ) เช่น
  What does the Account Status Lock(buy, sell) option indicate? 
  What does the Account Status Lock(buy) option indicate?
  What does the Account Status Lock(sell) option indicate? 

  เมื่อค้นหา ผลลัพธ์ที่ได้ใน Element ที่ 1 (ซึ่ง AI DB จะจัดอันดับความน่าจะเป็นของข้อความที่มีค่าความสัมพันธ์ กับ คำถาม ที่สุดไว้อันดับที่ 1 และ เรียงไปตามลำดับ) 

  สาเหตุ:
    ทดสอบค้นหาด้วย ChromaDb ผ่าน Langchain และ ใช้ ChromaDB แบบไม่ผ่าน Langchain  ผลลัพธ์ที่ได้ เหมือนกัน 
    แต่ 

    ในกรณีของการเรียก ChromaDB โดยไม่ผ่าน Langchain จะมีคุณสมบัติการค้นหา .query และกำหนด where ได้เฉพาะเจาะจงกว่า ทำให้ได้ผลลัพธ์ที่ถูกต้องมากกว่า

  แก้โดย:
    ในขั้นตอนการอ่านเอกสาร pdf, word, html, json, ... และ query ใช้ ChromaDB โดยที่่ไม่ผ่าน Langchain

  
 > LLM เมื่อสร้างคำตอบแล้วไม่ตัดประโยคให้
    A3 A: The Account Status options available in the system are CanBuy, CanSell, BuyBotton 
    Display, SellButton Display, Buy, Sell, Pending, Active, Lock(buy), Lock(sell), and 
    Lock(buy,sell).
    Q4 Q: Is it possible to buy and sell shares when the Share Status is CLOSEONLY? 
    A4 A: No, it is not possible to buy and sell shares when the Share Status is CLOSEONLY.    
    Q5 Q: What are the possible values for the CanBuy and CanSell Account Status 
    options?

    Question: Is it possible to buy and sell shares when the Share Status is CLOSEONLY? 

    ผลที่ได้:
      No, it is not possible to buy and sell shares when the Share Status is CLOSEONLY. Q5 Q: What are the possible 
      values for the CanBuy and CanSell Account Status options?

    สาเหตุ:
      เกิดจากข้อความที่ส่งให้กับ LLM ขาดรูปแบบของ End-Of-Sequence (EOS)/Stop Sequence หรือที่เรียกว่า จุดสิ้นสุดของลำดับ Token
      จะมีรูปแบบดังนี้
      1.) .\n เช่น  No, it is not possible to buy and sell shares when the Share Status is CLOSEONLY.\n
        เมื่อ LLM เจอรูปแบบ .\n ก็จะหยุดสร้างคำตอบทันที
      
    แก้โดย:
      1.) ให้เคาะ Space จำนวน 4 ครั้งต่อท้ายประโยค ก่อนขึ้นบรรทัดใหม่ และกำหนด n_bath = 1
      "No, it is not possible to buy and sell shares when the Share Status is CLOSEONLY." + Space 4 ครั้ง
      (ไม่แนะนำวิธีนี้ แต่ สามารถแก้ปัญหาได้ ให้ใช้วิธีที่ 2 ดีที่สุด)

      2.) รูปแบบของของข้อความที่ส่งให้กับ LLM ให้มี .\n  ลงท้าย เช่น
        No, it is not possible to buy and sell shares when the Share Status is CLOSEONLY.\n
        (แนะนำวิธีนี้)







+ 30/06/2023
 > ทำความเข้าใจ Parameter top_p, top_k และ n_predict
และปรับแต่งค่านี้ ที่ส่งให้กับ LLM เพื่อสร้างรูปประโยคในการตอบคำถาม
 > พบปัญหา ผลลัพธ์ที่ได้จากการใช้ from langchain.vectorstores import Chroma   การใช้ ChromaDb ผ่าน Langchain
  A. ผลลัพธ์จากการค้นหาไม่ตรงกับ คำถามที่ส่งเข้าไป และ การจัดลำดับดัชนี (index) ที่เรียงลำดับตาม distancing หรือ ความความน่าจะเป็นที่ใกล้เคียงกับคำถาม
เพี้ยน


